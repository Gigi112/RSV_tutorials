---
title: "Bayesian model in JAGS"
subtitle: "Tutorial 3 for transition"
author: "Zhe Zheng (Gigi)"
date: "2023-01-16"
fontsize: 10pt
output: 
  beamer_presentation:
  theme: CambridgeUS
  colortheme: "beaver"
  fonttheme: "structurebold"
---

```{r setup, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
require(rjags)
#"Note that the rjags package does not include a copy of  
# the JAGS you must install this separately.  
# For instructions on downloading JAGS,
# see the home page at https://mcmc-jags.sourceforge.io."
require(mcmcplots) # to plot the trace plots
require(coda) # for gelman diagnostic
```

## Outline

In this tutorial, we will learn how to use JAGS (Just Another Gibbs Sampler) in R to estimate unknown parameters with Markov Chain Monte Carlo (MCMC) methods in Bayesian framework. If you are interested in learning more about the theoretical knowledge of MCMC and Bayesian modeling, please check out courses "Probability and Statistics" (taught by Prof. Joseph Chang) and "Bayesian Statistics" (taught by Prof. Josh Warren). 
\
\
In the first section, we will introduce a simple jags model to help understand the syntax for rjags package.
\
\
In the second section, we will learn how to build up complicated models step by step (censor data and spatial autocorrelation). Before reading this section, you will need to familiar yourself with the RSV_timing_explain tutorials and a research article on the [relative RSV timing](https://doi.org/10.1111/irv.12965)

## Example 1: a simple jags model to estimate the unknown parameters

### First: Simulate a dataset for analysis

In this example, I simulate my own data in R in order to compare the MCMC results with our input parameters. I create a continuous outcome variable $y$ as a function of one predictor $x$ and an error term $\epsilon$ . I simulate 100 observations. The linear regression looks like
$$y=\beta_0+\beta_1x+\epsilon$$
**Our goal is to estimate the unknown parameters** $\boldsymbol{\beta_0}$ **and** $\boldsymbol{\beta_1}$ **given the observations and the linear relationship**

```{r}
n.sim=100; set.seed(123)
x=rnorm(n.sim, mean = 5, sd = 3)
epsilon=rnorm(n.sim, mean = 0, sd = 1)
beta0=5
beta1=3.2
y=beta0 + beta1 * x + epsilon
```

## Visualize the observations

Question: what is the intercept and slope for this linear regression?
```{r}
plot(x,y,type="p")
```

## rjags mamual

The following is quoted from rjags document, authored by Martyn Plummer:

"JAGS is a clone of BUGS (Bayesian analysis Using Gibbs Sampling). See Lunn et al (2009) for
a history of the BUGS project. Note that the rjags package does not include a copy of the JAGS
library: you must install this separately. For instructions on downloading JAGS, see the home page at https://mcmc-jags.sourceforge.io.
\
\
To fully understand how JAGS works, you need to read the JAGS User Manual. The manual explains the basics of modelling with JAGS and shows the functions and distributions available in the
dialect of the BUGS language used by JAGS. It also describes the command line interface. The
rjags package does not use the command line interface but provides equivalent functionality using
R functions."

## rjags mamual (continued)
\
\
"Analysis using the rjags package proceeds in steps:
1. Define the model using the BUGS language in a separate file.
\
\
2. Read in the model file using the jags.model function. This creates an object of class “jags”.
\
\
3. Update the model using the update method for “jags” objects. This constitutes a ‘burn-in’
period.
\
\
4. Extract samples from the model object using the coda.samples function. This creates an object of class “mcmc.list” which can be used to summarize the posterior distribution. The coda
package also provides convergence diagnostics to check that the output is valid for analysis
(see Plummer et al 2006)."

## Jags model structure (Step 1)

```{r}
basic_mod <-  "model{
 #model
  for(i in 1:n.sim){
   y[i] ~ dnorm(mu[i], tau)
# tau is the error term
   
   mu[i] = beta0 + beta1 * x[i]
# beta0 and beta1 are the unknown parameters
  }
  
 #priors; these are weakly informative priors
 beta0 ~ dnorm(0, 0.01)
# dnorm(mean, precision)
# precision = 0.01 --> var = 100
 beta1 ~ dnorm(0, 0.01)
 tau ~ dgamma(0.01,0.01)
# dgamma(shape,rate)
 }
 "
```

## Initialize model with known data and initial guess of unknown parameters (Step 2)

```{r}
######## Define known data ############
datalist=list("y"=y,"x"=x,"n.sim"=n.sim)

######## Set initial values for parameter estimate ######## 
inits=function(){list("beta0"=rnorm(1), "beta1"=rnorm(1))}
```

## Read in the model file using the jags.model function (Step 3)

```{r}
### Read in the model file using the jags.model function ##
jags.basic.mod = jags.model(textConnection(basic_mod),
                            data = datalist,
                            inits = inits,
                            n.chains = 4)
```


## Discard burn-in period and sample for posterior distribution (Step 4)

```{r,message=TRUE}
############ burn-in period ############
update(jags.basic.mod,5000) # n.burnin = 1000

##### sample for posterior distribution #######
model_sample <- coda.samples(jags.basic.mod,
                             c("beta0","beta1"),
                             100000,thin=5)
#You can also use jags.samples(). The results will be the same
```

## Summarize the posterior distribution 
```{r}
summary(model_sample)
```

## Check for model convergence (gelman diagnotics)

```{r}
gelman.diag(model_sample) ## <=1.1 means well converge 
```

## Check for model convergence (gelman plot)

```{r}
gelman.plot(model_sample)
```

## Plot the trace plot

```{r}
par(mfrow=c(1,2))
traceplot(model_sample)
```

## Compare the posterior density and real value for beta0  

```{r}
denplot(model_sample, parms = c("beta0"))
abline(v=5)  # True value
```

## Compare the posterior density and real value for beta1  

```{r}
denplot(model_sample, parms = c("beta1"))
abline(v=3.2) # True value
```

## Section 2: estimate the parameters for the relative RSV timing

After we estimated the [RSV timing](https://doi.org/10.1111/irv.12965) using second derivative method (please check: RSV_timing_explain), we would like to know if some potential drivers contribute to the relative timing difference in RSV epidemic onsets before and during COVID-19 pandemic.

The model is given as: 
$$Y_i=\alpha_{0i}+\beta_1\overline{Z_i}+\epsilon_i$$
$$\alpha_{0i}=\beta_0+\boldsymbol{x_i^T \lambda}+\theta_i$$

## Meaning of the variables and parameters

where $Y_i$ is the relative timing of RSV epidemic onset with respect to Florida in 2021 in state $i$ (measured in weeks), and $\overline{Z_i}$ is the average relative timing of RSV seasons in state $i$ compared to Florida from 2016-2019. The global intercept parameter $\beta_0$ and slope parameter $\beta_1$ describe the overall similarity between a typical year’s relative onset timing across all states and the relative timings observed in 2021. The observation-level random effect $\epsilon_i  ~ N(0,\sigma^2)$ accounts for residual variability in the data.
\
\
The state-specific intercepts, $\alpha_{0i}=\beta_0+\boldsymbol{x_i^T \lambda}+\theta_i$, represent the state-level similarity in relative timing for 2021 compared to previous seasons, where $x_i$ is the vector of covariates that could potentially explain differences in the relative timing of RSV between 2021 and previous years. The covariates include population density, average household size, and stringency index of non-pharmaceutical interventions against COVID-19. 
\
\
$\theta_i$ represents a spatially correlated random effect, which we will learn more in detail later.

## Jags model code without considering spatial autocorrelation

```{r}
Nospatial_model <- "model{
################ model ####################################
for(i in 1:n){
Y[i] ~ dnorm(mu[i], inv_var)
 mu[i] <- alpha_0[i] + beta1*log_Z[i]
 # log_Z is the log transform average relative timing of RSV  

alpha_0[i]= beta0+x1[i]*lambda1+x2[i]*lambda2+lambda3*x3[i]
# this is alpha_0i = beta0 + X_i*lambda (coviariates)
}

################ priors ####################################
beta0~dnorm(0,0.0001)
beta1~dnorm(0,0.0001)
lambda1~dnorm(0,0.0001)
lambda2~dnorm(0,0.0001)
lambda3~dnorm(0,0.0001)

inv_var ~ dgamma(0.01, 0.01)}"
```

## Load the data and run the jags model to sample posteriors  

```{r,eval=FALSE}
## loading data from the working directory
data <- readRDS("./Nospatial_model.rds")

### Read in the model file using the jags.model function ##
non_spatial <- jags.model(textConnection(Nospatial_model),
                     data=data,n.chains = 4)

############ burn-in period ############
update(non_spatial,10000)

######## sample for posterior distribution ##########
non_spatial_sample <- coda.samples(non_spatial,c("beta0","beta1",
                            "lambda1","lambda2",
                            "lambda3","inv_var"),
                             100000,thin=20)
```

## Summarize the posterior distribution

```{r,eval=FALSE}
summary(non_spatial_sample)
```

## Check for model convergence (gelman diagnostic)

```{r,eval=FALSE}
gelman.diag(non_spatial_sample)
```

## Trace plots

```{r,eval=FALSE}
par(mfrow=c(3,2))
traceplot(non_spatial_sample)
```

## Density plot of the posterior distributions

```{r,eval=FALSE}
par(mfrow=c(3,2))
densplot(non_spatial_sample)
```